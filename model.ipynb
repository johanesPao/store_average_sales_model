{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Sales Average Model\n",
    "---\n",
    "Notebook ini merupakan studi mengenai hubungan antara Jenis Bangunan, Kelas Bangunan, Lokasi Kabupaten/Kota dan Luas Area Toko dalam men-generate penjualan per bulan di PT Prestasi Retail Innovation.\n",
    "- Jenis Bangunan: Merupakan satu dari tiga tipe bangunan diantaranya Mall (M), Ruko (R) dan Bangunan Sendiri (S)\n",
    "- Kelas Bangunan: Merupakan kelas dari tipe bangunan tersebut dalam men-generate sales. Misalkan Mall Grand Indonesia adalah Mall Kelas 1 (M1) sedangkan Gandaria City adalah Mall Kelas 4 (M4). Berikut adalah Kelas Bangunan yang ada.\n",
    "  - Mall Kelas 1 (M1)\n",
    "  - Mall Kelas 2 (M2)\n",
    "  - Mall Kelas 3 (M3)\n",
    "  - Mall Kelas 4 (M4)\n",
    "  - Mall Kelas 5 (M5)\n",
    "  - Ruko Kelas 1 (R1)\n",
    "  - Ruko Kelas 2 (R2)\n",
    "  - Ruko Kelas 3 (R3)\n",
    "  - Ruko Kelas 4 (R4)\n",
    "  - Ruko Kelas 5 (R5)\n",
    "  - Bangunan Sendiri Kelas 1 (S1)\n",
    "  - Bangunan Sendiri Kelas 2 (S2)\n",
    "  - Bangunan Sendiri Kelas 3 (S3)\n",
    "  - Bangunan Sendiri Kelas 4 (S4)\n",
    "  - Bangunan Sendiri Kelas 5 (S5)\n",
    "- Lokasi Kabupaten/Kota adalah lokasi geografis dari toko\n",
    "- Luas Area Toko adalah luas meter persegi dari toko\n",
    "---\n",
    "Studi ini akan menggunakan Regresi Linear dalam merumuskan nilai Average Sales ($y$) yang dipengaruhi oleh variabel - variabel independen lainnya seperti Jenis Bangunan $x{_1}$, Kelas Bangunan $x{_2}$, Lokasi Kabupaten/Kota ($x{_3}$) dan Luas Area Toko ($x{_4}$). Berikut adalah formulasi Regresi Linear untuk permasalahan tersebut:  \n",
    "  \n",
    "$\n",
    "y = ax{_1} + bx{_2} + cx{_3} + dx{_4} + e\n",
    "$  \n",
    "  \n",
    "Dimana:  \n",
    "$y$ = Prediksi Average Sales  \n",
    "$x{_1}$ = Variabel independen mewakili Jenis Bangunan  \n",
    "$x{_2}$ = Variabel independen mewakili Kelas Bangunan  \n",
    "$x{_3}$ = Variabel independen mewakili Lokasi Kabupaten/Kota  \n",
    "$x{_4}$ = Variabel independen mewakili Luas Area Toko  \n",
    "$a$ = Koefisien variabel independen $x{_1}$  \n",
    "$b$ = Koefisien variabel independen $x{_2}$  \n",
    "$c$ = Koefisien variabel independen $x{_3}$  \n",
    "$d$ = Koefisien variabel independen $x{_4}$  \n",
    "$e$ = Bias dari Regresi Linear  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import lightgbm\n",
    "import xgboost\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "sns.set()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versi Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Tampilan DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,}'.format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksplorasi Data\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atribut Dasar Toko\n",
    "Berikut adalah beberapa data atribut dasar toko yang saat ini dimiliki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toko = pd.read_excel(\"PRI - Store Renov Rent.xlsx\", sheet_name=0, header=0)\n",
    "data_toko"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena kita tidak akan menggunakan semua kolom dalam data ini untuk kepentingan studi Store Sales Average, maka `data_toko` akan diringkas dan disusun ulang menjadi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toko = data_toko[[\"STORE CODE\", \"STORE NAME\", \"Tipe Bangunan\", \"Kelas Bangunan\", \"Kota Kabupaten 2\", \"Estimasi Populasi\", \"sqm\"]]\n",
    "data_toko"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Luas Area Toko (sqm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_luas = data_toko[\"sqm\"]\n",
    "hitung, bin = np.histogram(data_luas)\n",
    "print(hitung, bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = so.Plot(data_toko, \"sqm\")\n",
    "plot.add(so.Bars(), so.Hist(), legend=True).label(title=\"Persebaran Toko berdasar SQM\", x=\"Square Meters (sqm)\", y=\"Jumlah Toko\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan luasnya (sqm), kita dapat melihat pada fungsi `histogram` di atas bahwa distribusi persebaran luas toko cukup normal dengan 29 Toko jatuh ke dalam kategori `sqm` di antara $75m{^2}$ sampai dengan $150m{^2}$, dengan 1 toko yang menjadi outlier dari distribusi dimana luas toko > $400m{^2}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penjualan\n",
    "---\n",
    "Mengingat bahwa data *historical* yang dimiliki terbatas dari tahun 2018 sampai dengan November 2022, serta mengingat bahwa kita mengalami periode pandemi CoV-19 selama lebih dari 1 tahun, maka penulis merasa perlu untuk melakukan separasi data penjualan per bulan menggunakan flag `Pandemic`.\n",
    "  \n",
    "Berikut adalah sepenggal data penjualan *historical* per toko dari tahun 2018 sampai dengan November 2022 (40 baris data awal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_penjualan = pd.read_excel(\"PRI - Store Renov Rent.xlsx\", sheet_name=\"Sales\", header=0)\n",
    "data_penjualan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah grouping data penjualan *historical* yang disimpan dalam variabel `data_penjualan_by_month`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_penjualan_by_month = data_penjualan.groupby([\"EOM\"]).sum(numeric_only=True)\n",
    "data_penjualan_by_month"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk melihat trend pergerakan penjualan dalam kurun waktu ini, kita akan menggunakan `Simple Moving Average` yang akan menghitung rerata secara bergulung untuk interval waktu ke belakang (contoh: Moving Average 3 Bulan untuk Mei 2021 adalah rata - rata penjualan yang merupakan rata - rata dari penjualan di bulan Maret 2021, April 2021 dan Mei 2021).  \n",
    "Namun satu `Moving Average` saja tidak dapat menggambarkan sebuah trend, karena itu kita juga akan menggunakan tambahan 2 interval `Moving Average` lainnya untuk menggambarkan trend pada jangka pendek, jangka menengah dan jangka panjang.  \n",
    "Dalam studi ini kita akan menggunakan 3 `Simple Moving Average` yaitu:\n",
    "* `MA3`: `Moving Average` dengan jendela periode 3 bulan ke belakang (Jangka Pendek)\n",
    "* `MA6`: `Moving Average` dengan jendela periode 6 bulan ke belakang (Jangka Menengah)\n",
    "* `MA12`: `Moving Average` dengan jendela periode 12 bulan atau 1 tahun ke belakang (Jangka Panjang)  \n",
    "Berikut adalah `data_penjualan_by_month` dengan penambahan kolom `MA3`, `MA6` dan `MA12` yang didapat dengan menggunakan fungsi `rolling()` dari `pd.DataFrame` yang dirata-ratakan dengan fungsi `mean()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_penjualan_by_month[\"MA3\"] = data_penjualan_by_month[\"Sales\"].rolling(3).mean()\n",
    "data_penjualan_by_month[\"MA6\"] = data_penjualan_by_month[\"Sales\"].rolling(6).mean()\n",
    "data_penjualan_by_month[\"MA12\"] = data_penjualan_by_month[\"Sales\"].rolling(12).mean()\n",
    "data_penjualan_by_month"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah grafik penjualan *historical* dari tahun 2018 sampai dengan November 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garis_plot = so.Plot(data_penjualan_by_month, \"EOM\", \"Sales\")\n",
    "garis_plot.add(so.Line()).label(title=\"Total Penjualan per Bulan (2018 - Nov 2022)\", x=\"Tahun\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah grafik `Moving Average` untuk data penjualan *historical* dari tahun 2018 sampai dengan November 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_penjualan_by_month.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kolom_melt = pd.melt(data_penjualan_by_month.reset_index().drop(columns=[\"Sales\"]), id_vars='EOM', var_name=\"Tipe MA\", value_name=\"Nilai\")\n",
    "data_kolom_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(data_penjualan_by_month[\"MA3\"], color=\"green\", label=\"MA3\")\n",
    "# plt.plot(data_penjualan_by_month[\"MA6\"], color=\"orange\", label=\"MA6\")\n",
    "# plt.plot(data_penjualan_by_month[\"MA12\"], color=\"red\", label=\"MA12\")\n",
    "# plt.show()\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Moving Average Total Penjualan per Bulan\")\n",
    "ax.set_ylabel(\"Rata-Rata Total Penjualan per Bulan\")\n",
    "ax.set_xlabel(\"Tahun\")\n",
    "# Plot Moving Average\n",
    "sns.lineplot(data_kolom_melt, x=\"EOM\", y=\"Nilai\", hue=\"Tipe MA\")\n",
    "# Region Section Pandemic\n",
    "ax.fill_between(data_penjualan_by_month.index.values, 0, 28000000000, where=((data_penjualan_by_month.index.values > np.datetime64('2020-02-29')) & (data_penjualan_by_month.index.values <= np.datetime64('2021-10-31'))), color=\"red\", alpha=0.2)\n",
    "# Region Section Recovery\n",
    "ax.fill_between(data_penjualan_by_month.index.values, 0, 28000000000, where=((data_penjualan_by_month.index.values >= np.datetime64('2021-11-01')) & (data_penjualan_by_month.index.values <= np.datetime64('2022-12-31'))), color=\"green\", alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada grafik di atas kita dapat melihat bahwa terdapat tren penurunan penjualan (terkonfirmasi dengan `MA3` yang turun ke bawah `MA6` dan `MA12`) pada periode Maret 2020 (`Pandemic`) dan nilai rata - rata penjualan ini bertahan cukup rendah hingga setidaknya sampai dengan bulan Oktober 2021 dan di bulan November 2021 hingga seterusnya kita dapat melihat nilai rata-rata penjualan per bulan yang meningkat (`Recovery`, terkonfirmasi dengan `MA3` yang melewati dan bertahan di atas `MA6` dan `MA12`).  \n",
    "  \n",
    "Oleh karena itu kita akan mengkategorikan penjualan yang terjadi diantara bulan Maret 2020 - Oktober 2021 sebagai penjualan dalam masa `Pandemic` dan lainnya sebagai penjualan `Normal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandemic_period = [\n",
    "  np.datetime64('2020-03-31'),\n",
    "  np.datetime64('2020-04-30'),\n",
    "  np.datetime64('2020-05-31'),\n",
    "  np.datetime64('2020-06-30'),\n",
    "  np.datetime64('2020-07-31'),\n",
    "  np.datetime64('2020-08-31'),\n",
    "  np.datetime64('2020-09-30'),\n",
    "  np.datetime64('2020-10-31'),\n",
    "  np.datetime64('2020-11-30'),\n",
    "  np.datetime64('2020-12-31'),\n",
    "  np.datetime64('2021-01-31'),\n",
    "  np.datetime64('2021-02-28'),\n",
    "  np.datetime64('2021-03-31'),\n",
    "  np.datetime64('2021-04-30'),\n",
    "  np.datetime64('2021-05-31'),\n",
    "  np.datetime64('2021-06-30'),\n",
    "  np.datetime64('2021-07-31'),\n",
    "  np.datetime64('2021-08-31'),\n",
    "  np.datetime64('2021-09-30'),\n",
    "  np.datetime64('2021-10-31'),\n",
    "  ]\n",
    "print(pandemic_period)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah pengkategorian bulan penjualan berdasarkan periode `Pandemic` dan `Normal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_pandemi(x):\n",
    "  return \"Pandemic\" if x[\"EOM\"] in pandemic_period else \"Normal\"\n",
    "\n",
    "data_penjualan[\"Status Pandemi\"] = data_penjualan.apply(lambda x: status_pandemi(x), axis=1)\n",
    "data_penjualan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pembentukan dataframe `data_penjualan_rerata` untuk lookup nilai penjualan rata-rata pada masa pandemi dan normal di dataframe `data_toko`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_penjualan_rerata = data_penjualan.groupby(['Status Pandemi', 'LocationCode']).mean(numeric_only=True)\n",
    "data_penjualan_rerata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementasi lookup rata-rata penjualan per bulan untuk setiap toko baik pada masa pandemi maupun pada masa normal di dataframe `data_toko`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_rerata(x, pandemi_status, lookup_df):\n",
    "  try: \n",
    "    return sum(lookup_df.loc[pandemi_status, x['STORE CODE']].values)\n",
    "  except:\n",
    "    return np.NaN\n",
    "\n",
    "data_toko[\"Rerata Penjualan Normal\"] = data_toko.apply(lambda x: lookup_rerata(x, 'Normal', data_penjualan_rerata), axis=1) # type: ignore\n",
    "data_toko[\"Rerata Penjualan Pandemi\"] = data_toko.apply(lambda x: lookup_rerata(x, 'Pandemic', data_penjualan_rerata), axis=1) # type: ignore\n",
    "\n",
    "data_toko"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada dataframe `data_toko` dengan penambahan kolom `Rerata Penjualan Normal` dan `Rerata Penjualan Pandemi` kita dapat melihat bahwa nilai `Rerata Penjualan Normal` lebih besar daripada nilai `Rerata Penjualan Pandemi` untuk kesemua toko, hal ini menunjukkan bahwa kita berhasil menangkap nilai rata-rata penjualan per bulan di masa normal yang kita ekspektasikan menjadi acuan ke depannya.\n",
    "\n",
    "Nilai pada kolom `Rerata Penjualan Normal` ini adalah nilai $y$ yang sebenarnya. Nilai $y$ yang sebenarnya ini akan menjadi acuan dalam proses pelatihan jaringan saraf tiruan untuk melihat seberapa akurat model dalam memprediksi nilai $y$ atau yang kita sebut $\\hat{y}$ (*y-hat* atau prediksi y)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STORE CODE & KOTA KABUPATEN 2\n",
    "---\n",
    "Dalam membangun model prediksi, selain mempertimbangkan input dalam proses pelatihan model, kita juga harus mempertimbangkan interaksi pengguna dengan model nantinya dalam menghasilkan prediksi rata-rata penjualan per bulan.\n",
    "Jika kita membayangkan pengguna melakukan input pada serangkaian form untuk mendapatkan nilai output prediksi rata-rata penjualan per bulan untuk input yang diberikan, nampaknya akan sulit jika pengguna menginput semisalkan `STORE CODE` 'FS040' atau `KOTA KABUPATEN 2` 'PALU'. Hal ini dikarenakan model akan dilatih menggunakan data pada `data_toko` yang jumlah sampelnya sangat terbatas dan tidak pernah mengenal 'FS040' atau 'PALU' sebagai salah satu input dalam proses pelatihan model.  \n",
    "Oleh karena itu, kita akan melakukan modifikasi pada kedua variabel ini untuk memastikan proses pelatihan berjalan lebih umum (*general*) dan untuk memungkinkan input oleh pengguna pada model nantinya lebih umum."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STORE CODE\n",
    "Untuk `STORE CODE`, supaya baik proses pelatihan maupun input pada model nantinya bisa berlaku secara lebih umum, kita akan menggunakan `SBU` yang diekstrak dari dua karakter pertama dalam `STORE CODE` dan untuk FO akan masuk ke dalam `SBU` 'Fisik Sport'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def konversi_sbu(x):\n",
    "  try:\n",
    "    match x['STORE CODE'][:2]:\n",
    "      case \"FS\" | \"FO\":\n",
    "        return \"Fisik Sport\"\n",
    "      case \"FF\":\n",
    "        return \"Fisik Football\"\n",
    "      case \"OD\":\n",
    "        return \"Our Daily Dose\"\n",
    "      case _:\n",
    "        return np.NaN\n",
    "  except:\n",
    "    return np.NaN\n",
    "\n",
    "data_toko[\"SBU\"] = data_toko.apply(lambda x: konversi_sbu(x), axis=1) # type: ignore\n",
    "\n",
    "# Reorder kolom\n",
    "kolom = [\"STORE CODE\", \"STORE NAME\", \"SBU\", \"Tipe Bangunan\", \"Kelas Bangunan\", \"Kota Kabupaten 2\", \"Estimasi Populasi\", \"sqm\", \"Rerata Penjualan Normal\", \"Rerata Penjualan Pandemi\"]\n",
    "data_toko = data_toko[kolom]\n",
    "  \n",
    "data_toko"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KABUPATEN KOTA 2\n",
    "Untuk `KABUPATEN KOTA 2`, kita akan melakukan grouping rentang populasi, misalkan populasi `0 - 500,000`, `500,001 - 1,000,000` dstnya. Hal ini dipandang lebih baik untuk proses pelatihan jaringan saraf tiruan model dan juga untuk implementasi prediksi model pada aplikasi ke depannya, mengingat jumlah sampel pelatihan yang sangat terbatas.  \n",
    "Sebelumnya, dipandang perlu untuk melihat kardinalitas anggota dalam rentang yang terbentuk untuk memastikan distribusi yang mendekati normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumlah_anggota, bin = np.histogram(data_toko[\"Estimasi Populasi\"], bins=6, range=(0, 3000000))\n",
    "print(f\"Kardinalitas anggota: \\t{jumlah_anggota}\")\n",
    "print(f\"Range Bin: \\t\\t{bin}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada fungsi `histogram()` di atas kita mengelompokkan data `Estimasi Populasi` ke dalam 6 rentang dengan nilai rentang minimal dimulai dari 0 dan nilai rentang maksimal sebesar 3,000,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title(\"Persebaran Rentang Populasi Toko\")\n",
    "ax.hist(bin[:-1], weights=jumlah_anggota, range=(0, 3000000))\n",
    "ax.set_ylabel(\"Jumlah Toko di Kota dengan Rentang Populasi\")\n",
    "ax.set_xlabel(\"Rentang Populasi\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada grafik histogram di atas kita dapat melihat bahwa persebaran data cukup normal dimana sebagian besar toko dibuka di kota dengan populasi `1,000,000 - 1,500,000` (10 Toko) dan `1,500,001 - 2,000,000` (12 Toko) penduduk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def konversi_rentang_populasi(x):\n",
    "  try:\n",
    "    match x['Estimasi Populasi']:\n",
    "      case x if x <= 500000:\n",
    "        return '0 - 500000'\n",
    "      case x if x <= 1000000:\n",
    "        return '500001 - 1000000'\n",
    "      case x if x <= 1500000:\n",
    "        return '1000001 - 1500000'\n",
    "      case x if x <= 2000000:\n",
    "        return '1500001 - 2000000'\n",
    "      case x if x <= 2500000:\n",
    "        return '2000001 - 2500000'\n",
    "      case _:\n",
    "        return '> 2500000'\n",
    "  except:\n",
    "    return\n",
    "\n",
    "data_toko['Rentang Populasi'] = data_toko.apply(lambda x: konversi_rentang_populasi(x), axis=1) # type: ignore\n",
    "\n",
    "# Reorder kolom\n",
    "kolom = [\"STORE CODE\", \"STORE NAME\", \"SBU\", \"Tipe Bangunan\", \"Kelas Bangunan\", \"Kota Kabupaten 2\", \"Estimasi Populasi\", \"Rentang Populasi\", \"sqm\", \"Rerata Penjualan Normal\", \"Rerata Penjualan Pandemi\"]\n",
    "data_toko = data_toko[kolom]\n",
    "\n",
    "data_toko"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konversi Data Categorical ke dalam Label Encoder\n",
    "---\n",
    "Dengan dua perubahan pada sub-bagian sebelumnya maka fungsi regresi linear dapat digambarkan ulang sebagai berikut:  \n",
    "  \n",
    "$\n",
    "{Rerata Penjualan Normal} = a \\cdot {SBU} + b \\cdot {Kelas Bangunan} + c \\cdot {Luas Area} + d \\cdot {Rentang Populasi} + e\n",
    "$ \n",
    "   \n",
    "Dikarenakan `SBU`, `Kelas Bangunan` dan `Rentang Populasi` merupakan tipe data *categorical*, sedangkan pelatihan jaringan saraf tiruan untuk sebuah model memerlukan semua input dalam bentuk numerik, maka kita akan melakukan konversi pada ketiga data tersebut menjadi numerik.  \n",
    "Dilihat dari jenis datanya, `SBU` merupakan data *categorical nominal*, `Rentang Populasi` merupakan *categorical ordinal*, sedangkan `Kelas Bangunan` meski sekilas nampak seperti *categorical ordinal* dengan susunan hierarki dan memiliki bobot, namun hierarki dan bobot ini menjadi ambigu ketika kita beralih dari M5 ke R1 atau hierarki dan bobot yang tidak jelas antara R1 dan S1 mengenai mana yang lebih memiliki bobot, oleh karena itu untuk menjaga *prudentiality* dari model maka kita akan mengkategorikan `Kelas Bangunan` sebagai *categorical nominal* yang hanya merupakan label tanpa bobot antar kategori di dalamnya.  \n",
    "Untuk data *categorical nominal* kita akan menerapkan proses *One Hot Encoding* untuk menerapakan pelabelan numerik tanpa susunan maupun bobot dan untuk data *categorical ordinal* kita akan menggunakan *Ordinal Encoding*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding SBU dan Kelas Bangunan\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "sbu_encoded = ohe.fit_transform(data_toko[\"SBU\"].values.reshape(-1, 1)) # type: ignore\n",
    "data_sbu_encoded = pd.DataFrame(sbu_encoded, columns=ohe.get_feature_names_out([\"SBU\"]))\n",
    "kelas_bangunan_encoded = ohe.fit_transform(data_toko[\"Kelas Bangunan\"].values.reshape(-1, 1)) # type: ignore\n",
    "data_kelas_bangunan_encoded = pd.DataFrame(kelas_bangunan_encoded, columns=ohe.get_feature_names_out([\"Kelas Bangunan\"]))\n",
    "print(f\"Data SBU setelah proses One Hot Encoding: \\n{data_sbu_encoded}\")\n",
    "print(f\"Data Kelas Bangunan setelah proses One Hot Encoding: \\n{data_kelas_bangunan_encoded.to_string()}\")\n",
    "\n",
    "# Ordinal Encoding Rentang Populasi\n",
    "oe = OrdinalEncoder()\n",
    "rentang_populasi_encoded = oe.fit_transform(data_toko[\"Rentang Populasi\"].values.reshape(-1, 1)) # type: ignore\n",
    "data_rentang_populasi_encoded = pd.DataFrame(rentang_populasi_encoded, columns=[\"Rentang Populasi Encoded\"])\n",
    "print(f\"Data Rentang Populasi setelah proses Ordinal Encoding: \\n{data_rentang_populasi_encoded.to_string()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy data_toko\n",
    "data_model = data_toko.copy()\n",
    "\n",
    "# Penambahan data yang sudah melalui proses encoding\n",
    "data_model = pd.concat([data_model, data_sbu_encoded, data_kelas_bangunan_encoded, data_rentang_populasi_encoded], axis=1)\n",
    "\n",
    "# data_model sebelum drop data yang tidak digunakan dalam pelatihan\n",
    "data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop data yang tidak dipergunakan dalam pelatihan\n",
    "data_model = data_model.drop([\"STORE CODE\", \"STORE NAME\", \"SBU\", \"Tipe Bangunan\", \"Kelas Bangunan\", \"Kota Kabupaten 2\", \"Estimasi Populasi\", \"Rentang Populasi\", \"Rerata Penjualan Pandemi\"], axis=1)\n",
    "# Drop data dengan Rerata Penjualan Normal yang NaN\n",
    "data_model.dropna(subset=\"Rerata Penjualan Normal\", axis=0, inplace=True)\n",
    "\n",
    "# Data untuk proses pelatihan model\n",
    "data_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dan berikut adalah distribusi variabel independen terkait dengan variable independen lainnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=data_model, diag_kind='kde')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling dan Pembentukan Data Train Test\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Merujuk kepada nilai dalam data yang dimiliki, kita sebenarnya hanya memiliki 1 fitur (kolom) dengan nilai numerik, yaitu kolom `sqm` sedangkan sisanya merupakan kategori yang di-encode baik secara One Hot Encoding maupun Label Encoding. Meski *scale* antara `sqm` dan `Rerata Penjualan Normal` cukup jauh, namun mengingat `sqm` adalah bagian dari fitur ($x$) sedangkan `Rerata Penjualan Normal` adalah target ($y$), maka kita tidak perlu melakukan *scaling* pada fitur ($x$)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembentukan Data Train Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data X y\n",
    "Data X yang akan dipergunakan sebagai fitur adalah semua kolom pada `data_model` terkecuali kolom `Rerata Penjualan Normal` yang akan menjadi Data y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_model.drop(\"Rerata Penjualan Normal\", axis=1)\n",
    "y = data_model[\"Rerata Penjualan Normal\"]\n",
    "print(\"Data X:\")\n",
    "print(X.to_string())\n",
    "print(\"\\nData y:\")\n",
    "print(y.to_string())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Train Test\n",
    "Pembagian data train dan test adalah dengan rasio data test sebesar 0.2 dari total data, menggunakan random_state yang di-set pada 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12, shuffle=True)\n",
    "print(f\"X_train:\\n{X_train.to_string()}\\n\") # type: ignore\n",
    "print(f\"y_train:\\n{y_train.to_string()}\\n\") # type: ignore\n",
    "print(f\"X_test:\\n{X_test.to_string()}\\n\") # type: ignore\n",
    "print(f\"y_test:\\n{y_test.to_string()}\") # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembentukan Model\n",
    "Pada bagian ini kita akan coba untuk membuat beberapa model yang akan dipergunakan dalam pelatihan nantinya. Pelatihan model akan dilakukan menggunakan modul regressor pada TensorFlow, Scikit, LGBM dan XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TENSORFLOW MODEL\n",
    "class TensorFlow:\n",
    "  # Inisiasi kelas dan parameter model\n",
    "  def __init__(self, \n",
    "               fitur_train: pd.DataFrame, \n",
    "               target_train: pd.DataFrame,\n",
    "               fitur_test: pd.DataFrame,\n",
    "               target_test: pd.DataFrame,\n",
    "               random_seed: int = 11,\n",
    "               es_patience: int = 0,\n",
    "               callbacks: list = [],\n",
    "               loss: Literal[\"mae\", \"mse\"] = \"mae\",\n",
    "               optimizer: Literal[\"adam\", \"sgd\", \"adadelta\"] = \"adam\",\n",
    "               optimizer_lr: float = 0.01,\n",
    "               metric: list = ['mean_absolute_error'],\n",
    "               epoch: int = 100,\n",
    "               verbose_mode: int = 0):\n",
    "    self.fitur_train = fitur_train\n",
    "    self.target_train = target_train\n",
    "    self.fitur_test = fitur_test\n",
    "    self.target_test = target_test\n",
    "    self.random_seed = random_seed\n",
    "    self.es_patience = es_patience\n",
    "    self.callbacks = callbacks\n",
    "    if len(self.callbacks) == 0:\n",
    "      self.callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10 if self.es_patience <= 0 else self.es_patience)]\n",
    "    self.optimizer_lr = optimizer_lr\n",
    "    self.metric = metric\n",
    "    self.epoch = epoch\n",
    "    match loss:\n",
    "      case \"mse\":\n",
    "        self.loss = tf.keras.losses.mse\n",
    "      case _:\n",
    "        self.loss = tf.keras.losses.mae\n",
    "    match optimizer:\n",
    "      case \"sgd\":\n",
    "        self.optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=self.optimizer_lr)\n",
    "      case \"adadelta\":\n",
    "        self.optimizer = tf.keras.optimizers.legacy.Adadelta(learning_rate=self.optimizer_lr)\n",
    "      case _:\n",
    "        self.optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=self.optimizer_lr)\n",
    "    self.verbose_mode = verbose_mode\n",
    "        \n",
    "  # Compile model\n",
    "  def compile_model(self, model):\n",
    "    model.compile(loss=self.loss,\n",
    "                  optimizer=self.optimizer,\n",
    "                  metrics=self.metric)\n",
    "    \n",
    "  # Fit model\n",
    "  def fit_model(self, model):\n",
    "    return model.fit(self.fitur_train, \n",
    "                     self.target_train, \n",
    "                     epochs=self.epoch, \n",
    "                     validation_data=(self.fitur_test, self.target_test), \n",
    "                     callbacks=self.callbacks, \n",
    "                     verbose=self.verbose_mode)\n",
    "  \n",
    "  # Plotting nilai sebenarnya dan prediksi\n",
    "  def plot_hasil(self):\n",
    "    return\n",
    "  \n",
    "  # Model_Regresi_linear_1_Layer\n",
    "  def model_dense_1_layer(self,\n",
    "                          nama_model: str = \"\"):\n",
    "    # Set random seed\n",
    "    tf.random.set_seed = self.random_seed\n",
    "    # Model Def\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(1, input_dim=X_train.shape[1]) # type: ignore\n",
    "    ], name=nama_model)\n",
    "    self.compile_model(model)\n",
    "    return model\n",
    "  \n",
    "  # Model_Regresi_Linear_3_Layer_2_RELU\n",
    "  def model_dnn_3_layer(self, \n",
    "                        unit_1: int = 64, \n",
    "                        unit_2: int = 64,\n",
    "                        nama_model: str = \"\"):\n",
    "    # Set random seed\n",
    "    tf.random.set_seed = self.random_seed\n",
    "    # Model Def\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(unit_1, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(unit_2, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(1)\n",
    "    ], name=nama_model)\n",
    "    self.compile_model(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SCIKIT MODEL\n",
    "class SK:\n",
    "  # Inisiasi kelas dan parameter model\n",
    "  def __init__(self, \n",
    "               fitur_train: pd.DataFrame, \n",
    "               target_train: pd.DataFrame,\n",
    "               fitur_test: pd.DataFrame,\n",
    "               target_test: pd.DataFrame):\n",
    "    self.fitur_train = fitur_train\n",
    "    self.target_train = target_train\n",
    "    self.fitur_test = fitur_test\n",
    "    self.target_test = target_test\n",
    "    \n",
    "  # Fit model\n",
    "  def fit_model(self, model):\n",
    "    return model.fit(self.fitur_train, self.target_train)\n",
    "  \n",
    "  # Plotting nilai sebenarnya dan prediksi\n",
    "  def plot_hasil(self):\n",
    "    return\n",
    "  \n",
    "  # Model_SK_Linear_Regresi\n",
    "  def regresi_linear(self):\n",
    "    return LinearRegression()\n",
    "  \n",
    "  # Model_SK_Decision_Tree\n",
    "  def decision_tree(self):\n",
    "    return DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIGHTBM DAN XGBOOST MODEL (ENSEMBLE REGRESSOR)\n",
    "class EnsembleModel:\n",
    "  def __init__(self,\n",
    "               fitur_train: pd.DataFrame,\n",
    "               target_train: pd.DataFrame,\n",
    "               fitur_test: pd.DataFrame,\n",
    "               target_test: pd.DataFrame):\n",
    "    self.fitur_train = fitur_train\n",
    "    self.target_train = target_train\n",
    "    self.fitur_test = fitur_test\n",
    "    self.target_test = target_test\n",
    "  \n",
    "  def fit_model(self, model):\n",
    "    return model.fit(self.fitur_train, self.target_train)\n",
    "  \n",
    "  def lgbm(self):\n",
    "    return lightgbm.LGBMRegressor()\n",
    "  \n",
    "  def xgb(self):\n",
    "    return xgboost.XGBRFRegressor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pelatihan Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow = TensorFlow(\n",
    "  fitur_train=X_train, # type: ignore\n",
    "  target_train=y_train, # type: ignore\n",
    "  fitur_test=X_test, # type: ignore\n",
    "  target_test=y_test, # type: ignore\n",
    "  es_patience=20,\n",
    "  epoch=1000\n",
    ")\n",
    "\n",
    "tensorflow_model = [tensorflow.model_dense_1_layer(\"Model_Dense_1_Layer\"), tensorflow.model_dnn_3_layer(nama_model=\"Model_DNN_3_Layer_RELU_64_64\"), tensorflow.model_dnn_3_layer(128, 64, \"Model_DNN_3_Layer_RELU_128_64\")]\n",
    "\n",
    "for index, model in enumerate(tensorflow_model):\n",
    "  # plot_model(model, show_shapes=True)\n",
    "  # model.summary()\n",
    "  hasil = tensorflow.fit_model(model)\n",
    "  if index != 0:\n",
    "    print(\"\\n\")\n",
    "  print(f\"Model {index + 1} Summary dan Mean Absolute Error:\\n\")\n",
    "  model.summary()\n",
    "  print(tf.keras.losses.mean_absolute_error(y_test, model.predict(X_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
